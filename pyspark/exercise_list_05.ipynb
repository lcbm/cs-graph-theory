{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise List 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando o Apache Spark e demais ferramentas correlatas, implemente os seguintes passos:\n",
    "\n",
    "1. Selecione um estado brasileiro e dez de suas cidades. \n",
    "    - Crie um CSV para armazenar as cidades, com: `id` (nome da cidade), `latitude`, `longitude` e `população`.\n",
    "    - Crie outro CSV para armazenar a distância entre essas cidades, com: `src`, `dst` e `relationship` como campos.\n",
    "        - adicione pelo menos 30 registros nesse arquivo.\n",
    "2. Utilizando as bibliotecas do Spark, crie um objeto `GraphFrame` a partir desses dois CSVs.\n",
    "3. Utilizando o método `bfs` (Breadth First Search), execute **5** filtragens a sua escolha.\n",
    "4. Execute 2 consultas utilizando o método `find`.\n",
    "5. Execute 2 consultas utilizando o método `filterVertices`.\n",
    "6. Implemente uma rotina que, recebendo como entrada um objeto `GraphFrame`, percorra todos os vértices do grafo com o algoritmo da busca em profundidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "conf = SparkConf().setAppName('appName').setMaster('local')\n",
    "sc = SparkContext.getOrCreate(conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Selecione um estado brasileiro e dez de suas cidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crie um CSV para armazenar as cidades, com: `id` (nome da cidade), `latitude`, `longitude` e `população`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------+----------+\n",
      "|       id|latitude|longitude|population|\n",
      "+---------+--------+---------+----------+\n",
      "|Araripina|  7.5766|  40.4976|     84418|\n",
      "|  Caruaru|  8.2760|  35.9819|    277982|\n",
      "| Igarassu|   78292|   349016|     91953|\n",
      "|  Cabrobo|  8.5082|  39.3103|     33856|\n",
      "|  Carpina|  7.8450|  35.2437|     81054|\n",
      "| Ouricuri|  7.8809|  40.0810|     69459|\n",
      "|  Surubim|  7.8543|  35.7630|     64520|\n",
      "|Petrolina|  9.3891|  40.5031|       217|\n",
      "|Salgueiro|  8.0725|  39.1268|     59769|\n",
      "|   Recife|  8.0522|  34.9286|   1555000|\n",
      "+---------+--------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cidades = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/transport/transport-nodes.csv\")\n",
    "cidades.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Crie outro CSV para armazenar a distância entre essas cidades, com: `src`, `dst` e `relationship` como campos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+------------+----+\n",
      "|      src|      dst|relationship|cost|\n",
      "+---------+---------+------------+----+\n",
      "|Araripina|  Caruaru|       EROAD| 551|\n",
      "|Araripina| Igarassu|       EROAD| 700|\n",
      "|Araripina|  Cabrobo|       EROAD| 186|\n",
      "|   Recife|  Surubim|       EROAD| 118|\n",
      "|   Recife|Salgueiro|       EROAD| 510|\n",
      "|   Recife|  Caruaru|       EROAD| 510|\n",
      "| Ouricuri| Igarassu|       EROAD| 641|\n",
      "| Ouricuri|  Surubim|       EROAD| 525|\n",
      "| Ouricuri|Salgueiro|       EROAD| 359|\n",
      "|  Cabrobo| Ouricuri|       EROAD| 127|\n",
      "|  Cabrobo|  Carpina|       EROAD| 502|\n",
      "|  Cabrobo|   Recife|       EROAD| 526|\n",
      "| Igarassu|Salgueiro|       EROAD| 529|\n",
      "| Igarassu| Ouricuri|       EROAD| 197|\n",
      "| Igarassu|   Recife|       EROAD|  28|\n",
      "|  Carpina|Petrolina|       EROAD| 681|\n",
      "|  Carpina|Salgueiro|       EROAD| 480|\n",
      "|  Carpina| Ouricuri|       EROAD| 591|\n",
      "|Petrolina| Ouricuri|       EROAD| 154|\n",
      "|Petrolina|  Surubim|       EROAD|  66|\n",
      "|Petrolina| Igarassu|       EROAD| 726|\n",
      "|  Surubim|Araripina|       EROAD| 583|\n",
      "|  Surubim|  Caruaru|       EROAD|  67|\n",
      "|  Surubim|Salgueiro|       EROAD| 413|\n",
      "|Salgueiro|Araripina|       EROAD| 171|\n",
      "|Salgueiro|  Cabrobo|       EROAD|  60|\n",
      "|Salgueiro|Petrolina|       EROAD| 234|\n",
      "|  Caruaru| Igarassu|       EROAD| 151|\n",
      "|  Caruaru|Petrolina|       EROAD| 576|\n",
      "|  Caruaru| Ouricuri|       EROAD| 492|\n",
      "+---------+---------+------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distancias = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/transport/transport-relationships.csv\")\n",
    "distancias.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
